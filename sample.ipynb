{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実践問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_dict = pd.read_csv('要因.csv', index_col=0).to_dict()['CAUSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unknown'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>nr</th>\n",
       "      <th>serial</th>\n",
       "      <th>error_code</th>\n",
       "      <th>factor</th>\n",
       "      <th>print_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020/1/1</td>\n",
       "      <td>2020/1/2</td>\n",
       "      <td>500-1</td>\n",
       "      <td>aaa</td>\n",
       "      <td>1</td>\n",
       "      <td>PQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020/1/2</td>\n",
       "      <td>2020/1/7</td>\n",
       "      <td>500-2</td>\n",
       "      <td>aaa</td>\n",
       "      <td>2</td>\n",
       "      <td>PQ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020/1/3</td>\n",
       "      <td>2020/2/7</td>\n",
       "      <td>500-3</td>\n",
       "      <td>aaa</td>\n",
       "      <td>4</td>\n",
       "      <td>JAM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020/1/4</td>\n",
       "      <td>2020/1/10</td>\n",
       "      <td>600-1</td>\n",
       "      <td>aaa</td>\n",
       "      <td>8</td>\n",
       "      <td>PQ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020/1/5</td>\n",
       "      <td>2020/2/20</td>\n",
       "      <td>600-1</td>\n",
       "      <td>aaa</td>\n",
       "      <td>3</td>\n",
       "      <td>Noise</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020/1/6</td>\n",
       "      <td>2020/3/20</td>\n",
       "      <td>600-1</td>\n",
       "      <td>aaa</td>\n",
       "      <td>2</td>\n",
       "      <td>Noise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020/1/7</td>\n",
       "      <td>2020/1/7</td>\n",
       "      <td>701-1</td>\n",
       "      <td>bbb</td>\n",
       "      <td>4</td>\n",
       "      <td>JAM</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020/1/8</td>\n",
       "      <td>2020/1/2</td>\n",
       "      <td>500-1</td>\n",
       "      <td>bbb</td>\n",
       "      <td>8</td>\n",
       "      <td>PQ</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020/1/9</td>\n",
       "      <td>2020/1/7</td>\n",
       "      <td>500-2</td>\n",
       "      <td>bbb</td>\n",
       "      <td>1</td>\n",
       "      <td>JAM</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020/1/10</td>\n",
       "      <td>2020/2/7</td>\n",
       "      <td>500-3</td>\n",
       "      <td>bbb</td>\n",
       "      <td>2</td>\n",
       "      <td>JAM</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020/1/11</td>\n",
       "      <td>2020/1/10</td>\n",
       "      <td>600-1</td>\n",
       "      <td>bbb</td>\n",
       "      <td>7392</td>\n",
       "      <td>PQ</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020/1/12</td>\n",
       "      <td>2020/2/20</td>\n",
       "      <td>600-1</td>\n",
       "      <td>bbb</td>\n",
       "      <td>8</td>\n",
       "      <td>Noise</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020/1/13</td>\n",
       "      <td>2020/3/20</td>\n",
       "      <td>600-1</td>\n",
       "      <td>bbb</td>\n",
       "      <td>1</td>\n",
       "      <td>Noise</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020/1/14</td>\n",
       "      <td>2020/1/7</td>\n",
       "      <td>701-1</td>\n",
       "      <td>bbb</td>\n",
       "      <td>2</td>\n",
       "      <td>JAM</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020/1/15</td>\n",
       "      <td>2020/1/7</td>\n",
       "      <td>801-1</td>\n",
       "      <td>bbb</td>\n",
       "      <td>4</td>\n",
       "      <td>JAM</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020/1/16</td>\n",
       "      <td>2020/1/7</td>\n",
       "      <td>801-1</td>\n",
       "      <td>ccc</td>\n",
       "      <td>8</td>\n",
       "      <td>JAM</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020/1/17</td>\n",
       "      <td>2020/1/7</td>\n",
       "      <td>801-1</td>\n",
       "      <td>ccc</td>\n",
       "      <td>1</td>\n",
       "      <td>JAM</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start        end     nr serial  error_code factor  print_count\n",
       "0    2020/1/1   2020/1/2  500-1    aaa           1     PQ            1\n",
       "1    2020/1/2   2020/1/7  500-2    aaa           2     PQ            2\n",
       "2    2020/1/3   2020/2/7  500-3    aaa           4    JAM            3\n",
       "3    2020/1/4  2020/1/10  600-1    aaa           8     PQ            4\n",
       "4    2020/1/5  2020/2/20  600-1    aaa           3  Noise            5\n",
       "5    2020/1/6  2020/3/20  600-1    aaa           2  Noise            6\n",
       "6    2020/1/7   2020/1/7  701-1    bbb           4    JAM            7\n",
       "7    2020/1/8   2020/1/2  500-1    bbb           8     PQ            8\n",
       "8    2020/1/9   2020/1/7  500-2    bbb           1    JAM            9\n",
       "9   2020/1/10   2020/2/7  500-3    bbb           2    JAM           10\n",
       "10  2020/1/11  2020/1/10  600-1    bbb        7392     PQ           11\n",
       "11  2020/1/12  2020/2/20  600-1    bbb           8  Noise           12\n",
       "12  2020/1/13  2020/3/20  600-1    bbb           1  Noise           13\n",
       "13  2020/1/14   2020/1/7  701-1    bbb           2    JAM           14\n",
       "14  2020/1/15   2020/1/7  801-1    bbb           4    JAM           15\n",
       "15  2020/1/16   2020/1/7  801-1    ccc           8    JAM           16\n",
       "16  2020/1/17   2020/1/7  801-1    ccc           1    JAM           17"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('test1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aaa', 'bbb', 'ccc'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviceid_list = df.serial.unique()\n",
    "deviceid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         start        end     nr serial  error_code factor  print_count\n",
      "0    2020/1/1   2020/1/2  500-1    aaa           1     PQ            1\n",
      "1    2020/1/2   2020/1/7  500-2    aaa           2     PQ            2\n",
      "2    2020/1/3   2020/2/7  500-3    aaa           4    JAM            3\n",
      "3    2020/1/4  2020/1/10  600-1    aaa           8     PQ            4\n",
      "4    2020/1/5  2020/2/20  600-1    aaa           3  Noise            5\n",
      "5    2020/1/6  2020/3/20  600-1    aaa           2  Noise            6\n",
      "6    2020/1/7   2020/1/7  701-1    bbb           4    JAM            7\n",
      "7    2020/1/8   2020/1/2  500-1    bbb           8     PQ            8\n",
      "8    2020/1/9   2020/1/7  500-2    bbb           1    JAM            9\n",
      "9   2020/1/10   2020/2/7  500-3    bbb           2    JAM           10\n",
      "10  2020/1/11  2020/1/10  600-1    bbb        7392     PQ           11\n",
      "11  2020/1/12  2020/2/20  600-1    bbb           8  Noise           12\n",
      "12  2020/1/13  2020/3/20  600-1    bbb           1  Noise           13\n",
      "13  2020/1/14   2020/1/7  701-1    bbb           2    JAM           14\n",
      "14  2020/1/15   2020/1/7  801-1    bbb           4    JAM           15\n",
      "2         start       end     nr serial  error_code factor  print_count\n",
      "15  2020/1/16  2020/1/7  801-1    ccc           8    JAM           16\n",
      "16  2020/1/17  2020/1/7  801-1    ccc           1    JAM           17\n"
     ]
    }
   ],
   "source": [
    "n = round(len(deviceid_list)/2)\n",
    "\n",
    "for i in range(0, len(deviceid_list), n):\n",
    "    device = deviceid_list[i: i+n]\n",
    "    _df = df[df.serial.isin(device)]\n",
    "    print(i,_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 3, 2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "カテゴリと記事タイトルがnews_titles_and_categories.csvに保存されました。\n"
     ]
    }
   ],
   "source": [
    "# Yahoo!ニュースのトピック一覧ページからタイトルとカテゴリを取得\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_titles_and_categories(url):\n",
    "    # URLにアクセスしてページのHTMLを取得\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # 各カテゴリーとその記事タイトルを抽出\n",
    "    sections = soup.find_all('div', class_='sc-hwj2au-1')\n",
    "    data = []\n",
    "\n",
    "    for section in sections:\n",
    "        category = section.find('a').get_text(strip=True)\n",
    "        articles = section.find_all('li', class_='sc-1nhdoj2-0')\n",
    "        for article in articles:\n",
    "            title = article.find('a').get_text(strip=True)\n",
    "            data.append({\"Category\": category, \"Title\": title})\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Yahoo!ニュースのトピック一覧ページからタイトルとカテゴリを取得\n",
    "url = \"https://news.yahoo.co.jp/topics\"\n",
    "data = get_titles_and_categories(url)\n",
    "\n",
    "# データをデータフレームに変換\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# データフレームをCSVファイルに保存\n",
    "df.to_csv('news_titles_and_categories.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"カテゴリと記事タイトルがnews_titles_and_categories.csvに保存されました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "以下のサイトから、一ヶ月以内に更新された「製品・ソリューション」の情報のみを取得するPythonのコードを教えてください。\n",
    "情報がある場合は、pandasを用いて、csvファイルで出力してください。\n",
    "コメントは日本語で書いてください。\n",
    "https://www.kyoceradocumentsolutions.com/ja/news/rls_2024/\n",
    "\n",
    "一つの記事は、以下のような構成です。\n",
    "この記事の場合は、2024/12/09が更新日で、「製品・ソリューション」の情報です。\n",
    "<li>\n",
    "                        <div class=\"news-entries__date\">2024/12/09</div>\n",
    "                        <div class=\"news-entries__category\">\n",
    "                            <a href=\"/ja/news/products-solutions/\">製品・ソリューション</a>\n",
    "                        </div>\n",
    "                        <div class=\"news-entries__title\"><a href=\"/ja/news/rls_2024/rls_20241209.html\">カラーA4プリンターECOSYS PA2600cwx、カラーA4複合機ECOSYS MA2600cwfxを新発売</a></div>\n",
    "                    </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVファイルに出力しました\n"
     ]
    }
   ],
   "source": [
    "# ニュースサイトから、一ヶ月以内の記事を取得する\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 基本URLを設定します\n",
    "base_url = \"https://www.kyoceradocumentsolutions.com\"\n",
    "\n",
    "# ニュースのURLを設定します\n",
    "news_url = \"https://www.kyoceradocumentsolutions.com/ja/news/rls_2024/\"\n",
    "\n",
    "# ページを取得します\n",
    "response = requests.get(news_url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# 現在の日付を取得します\n",
    "now = datetime.now()\n",
    "one_month_ago = now - timedelta(days=40)\n",
    "\n",
    "# データを格納するリストを準備します\n",
    "data = []\n",
    "\n",
    "# ニュースエントリーをすべて抽出します\n",
    "entries = soup.find_all(\"li\")\n",
    "for entry in entries:\n",
    "    date_div = entry.find(\"div\", class_=\"news-entries__date\")\n",
    "    category_div = entry.find(\"div\", class_=\"news-entries__category\")\n",
    "    title_div = entry.find(\"div\", class_=\"news-entries__title\")\n",
    "    \n",
    "    # 必要な要素がすべて存在するか確認します\n",
    "    if date_div and category_div and title_div:\n",
    "        date_str = date_div.text.strip()\n",
    "        category = category_div.text.strip()\n",
    "        title = title_div.text.strip()\n",
    "        relative_link = title_div.find(\"a\")[\"href\"]\n",
    "        full_link = base_url + relative_link  # フルパスに変換\n",
    "        \n",
    "        # 日付をdatetimeオブジェクトに変換します\n",
    "        entry_date = datetime.strptime(date_str, \"%Y/%m/%d\")\n",
    "        \n",
    "        # カテゴリが「製品・ソリューション」であり、かつ一ヶ月以内に更新された記事のみを抽出します\n",
    "        if category == \"製品・ソリューション\" and entry_date >= one_month_ago:\n",
    "            data.append([entry_date, category, title, full_link])\n",
    "\n",
    "# pandasのDataFrameを作成します\n",
    "df = pd.DataFrame(data, columns=[\"日付\", \"カテゴリ\", \"タイトル\", \"リンク\"])\n",
    "\n",
    "# DataFrameをcsvファイルに出力します\n",
    "df.to_csv(\"products_solutions_updates.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"CSVファイルに出力しました\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     講師名      所属企業        生年月日   出身  \\\n",
      "0  今西 航平       NaN         NaN  NaN   \n",
      "1    NaN  株式会社キカガク         NaN  NaN   \n",
      "2    NaN       NaN  1994年7月15日  NaN   \n",
      "3    NaN       NaN         NaN  千葉県   \n",
      "4    NaN       NaN         NaN  NaN   \n",
      "\n",
      "                                                  趣味  \n",
      "0                                                NaN  \n",
      "1                                                NaN  \n",
      "2                                                NaN  \n",
      "3                                                NaN  \n",
      "4  \\n              バスケットボール\\n              読書\\n  ...  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Safari WebDriverを設定します\n",
    "driver = webdriver.Safari()\n",
    "\n",
    "# 指定されたURLにアクセスします\n",
    "driver.get(\"https://scraping-for-beginner.herokuapp.com/login_page\")\n",
    "\n",
    "# ユーザ名とパスワードを入力します\n",
    "username = driver.find_element(By.ID, \"username\")\n",
    "password = driver.find_element(By.ID, \"password\")\n",
    "\n",
    "username.send_keys(\"imanishi\")  # ここに実際のユーザ名を入力してください\n",
    "password.send_keys(\"kohei\")  # ここに実際のパスワードを入力してください\n",
    "\n",
    "# ログインボタンをクリックします\n",
    "login_button = driver.find_element(By.CLASS_NAME, \"btn\")\n",
    "login_button.click()\n",
    "\n",
    "# ログイン後のページが読み込まれるまで少し待機します\n",
    "time.sleep(5)\n",
    "\n",
    "# 表を取得します\n",
    "table = driver.find_element(By.TAG_NAME, \"table\")\n",
    "\n",
    "# 表の行データを解析して辞書リストに変換します\n",
    "rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "data = []\n",
    "\n",
    "for row in rows:\n",
    "    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    column_name = row.find_element(By.TAG_NAME, \"th\").text\n",
    "    value = cells[0].text if len(cells) > 0 else \"\"\n",
    "    data.append({column_name: value})\n",
    "\n",
    "# DataFrameに変換します\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# DataFrameを表示します\n",
    "print(df)\n",
    "\n",
    "# 必要に応じてCSVファイルに保存します\n",
    "df.to_csv(\"mypage_table.csv\", index=False)\n",
    "\n",
    "# ブラウザを閉じます\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "以下のサイトから、一ヶ月以内に更新されたの情報のみを取得するPythonのコードを教えてください。\n",
    "情報がある場合は、pandasを用いて、csvファイルで出力してください。\n",
    "コメントは日本語で書いてください。\n",
    "https://newsroom.lexmark.com/newsreleases\n",
    "\n",
    "一つの記事は、以下のような構成です。\n",
    "この記事の場合は、2025/1/7が更新日で、「Lexmark Named 2025 Leader in LGBTQ+ Workplace Inclusion」の情報です。<li class=\"wd_item\">\n",
    "<div class=\"wd_item_wrapper\">\n",
    "\t<div class=\"wd_date\">Jan 7, 2025</div>\n",
    "\t<div class=\"wd_title\"><a href=\"https://newsroom.lexmark.com/2025-01-07-Lexmark-Named-2025-Leader-in-LGBTQ-Workplace-Inclusion\">Lexmark Named 2025 Leader in LGBTQ+ Workplace Inclusion</a></div>\n",
    "\t\n",
    "\t<div class=\"wd_summary\"><p>Kentucky-based company has been recognized in Human Rights Campaign Foundation's Corporate Equality Index each year since survey began LEXINGTON, Ky., Jan. 7, 2025 /PRNewswire/ -- Lexmark, a...</p></div>\n",
    "\t\n",
    "\t\n",
    "</div>\n",
    "</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVファイルが生成されました。\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 現在の日付を取得します\n",
    "current_date = datetime.now()\n",
    "\n",
    "# サイトのURL\n",
    "url = \"https://newsroom.lexmark.com/newsreleases\"\n",
    "\n",
    "# リクエストを送信してHTMLを取得します\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# ニュース記事を取得します\n",
    "articles = soup.find_all(\"li\", class_=\"wd_item\")\n",
    "\n",
    "# データを格納するリスト\n",
    "data = []\n",
    "\n",
    "# 各記事を解析します\n",
    "for article in articles:\n",
    "    date_str = article.find(\"div\", class_=\"wd_date\").text.strip()\n",
    "    date = datetime.strptime(date_str, \"%b %d, %Y\")\n",
    "    title = article.find(\"div\", class_=\"wd_title\").text.strip()\n",
    "    summary = article.find(\"div\", class_=\"wd_summary\").text.strip()\n",
    "    \n",
    "    # 更新日が一ヶ月以内かどうかを確認します\n",
    "    if (current_date - date) <= timedelta(days=30):\n",
    "        data.append({\n",
    "            \"更新日\": date_str,\n",
    "            \"タイトル\": title,\n",
    "            \"概要\": summary\n",
    "        })\n",
    "\n",
    "# データをDataFrameに変換します\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# CSVファイルに保存します\n",
    "df.to_csv(\"recent_articles.csv\", index=False)\n",
    "\n",
    "print(\"CSVファイルが生成されました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "以下の #要件 を満たすPython のコードを作成してください。\n",
    "#前程条件：\n",
    "・特定のフォルダ内に複数のcsvファイルがある\n",
    "\n",
    "#要件：\n",
    "・ライブラリは、tkinterを使用する\n",
    "・任意のキーワードを入力すると、そのキーワードが文字内部に含まれるcsvファイルを検索する\n",
    "・検索フォルダは、pythonファイルと同じフォルダ内とする\n",
    "・検索する文字列は、部分一致でも可として、大文字と小文字は区別しない\n",
    "・複数の検索結果があるときには、すべて表示する\n",
    "・検索された「csvファイル名」と「検索されたセル内の文字列全体」を表形式で表示する\n",
    "・表示されたファイル名をクリックした場合、csvファイルが開くことができる\n",
    "・検索のステータスバーを表示する\n",
    "・GUIのデフォルトサイズは800×800とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk\n",
    "\n",
    "# キーワードでCSVファイルを検索する関数\n",
    "def search_csv_files(keyword):\n",
    "    results = []\n",
    "    keyword = keyword.lower()\n",
    "    for file in os.listdir('.'):\n",
    "        if file.endswith('.csv'):\n",
    "            with open(file, newline='', encoding='utf-8') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                for row in reader:\n",
    "                    for cell in row:\n",
    "                        if keyword in cell.lower():\n",
    "                            results.append((file, cell))\n",
    "                            break\n",
    "    return results\n",
    "\n",
    "# 検索ボタンがクリックされたときに呼び出される関数\n",
    "def on_search():\n",
    "    keyword = keyword_entry.get()\n",
    "    if not keyword:\n",
    "        messagebox.showwarning(\"入力エラー\", \"キーワードを入力してください\")\n",
    "        return\n",
    "\n",
    "    status_label.config(text=\"検索中...\")\n",
    "    root.update_idletasks()\n",
    "\n",
    "    results = search_csv_files(keyword)\n",
    "    for row in tree.get_children():\n",
    "        tree.delete(row)\n",
    "\n",
    "    if results:\n",
    "        for file, cell in results:\n",
    "            tree.insert(\"\", \"end\", values=(file, cell))\n",
    "    else:\n",
    "        messagebox.showinfo(\"結果なし\", \"該当するCSVファイルが見つかりませんでした\")\n",
    "\n",
    "    status_label.config(text=\"検索完了\")\n",
    "\n",
    "# CSVファイルを開く関数\n",
    "def open_csv_file(event):\n",
    "    item = tree.identify('item', event.x, event.y)\n",
    "    if not item:\n",
    "        return\n",
    "\n",
    "    file = tree.item(item, 'values')[0]\n",
    "    os.startfile(file)\n",
    "\n",
    "# GUIのセットアップ\n",
    "root = tk.Tk()\n",
    "root.title(\"CSVファイル検索\")\n",
    "root.geometry(\"800x800\")\n",
    "\n",
    "frame = ttk.Frame(root)\n",
    "frame.pack(padx=10, pady=10, fill=\"x\", expand=True)\n",
    "\n",
    "keyword_label = ttk.Label(frame, text=\"キーワード:\")\n",
    "keyword_label.pack(side=\"left\", padx=(0, 10))\n",
    "\n",
    "keyword_entry = ttk.Entry(frame)\n",
    "keyword_entry.pack(side=\"left\", fill=\"x\", expand=True)\n",
    "\n",
    "search_button = ttk.Button(frame, text=\"検索\", command=on_search)\n",
    "search_button.pack(side=\"left\", padx=(10, 0))\n",
    "\n",
    "tree = ttk.Treeview(root, columns=(\"ファイル名\", \"内容\"), show=\"headings\")\n",
    "tree.heading(\"ファイル名\", text=\"ファイル名\")\n",
    "tree.heading(\"内容\", text=\"内容\")\n",
    "tree.pack(padx=10, pady=10, fill=\"both\", expand=True)\n",
    "\n",
    "tree.bind(\"<Double-1>\", open_csv_file)\n",
    "\n",
    "status_label = ttk.Label(root, text=\"ステータスバー\")\n",
    "status_label.pack(side=\"bottom\", fill=\"x\")\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "昨年度取り組んできた、データ活用推進チームの活動報告を行います。\n",
    "その中で、EALデータ活用を浸透させる為に必要な施策に関する話を中心に説明させていただきます。\n",
    "\n",
    "昨年度、データ活用を第一開発センターに浸透させることを目的に、データ活用推進チームを発足させました。\n",
    "こういった各部門のデータ活用に長けたメンバーや、FW DX推進活動と連携して活動をしてきました。\n",
    "\n",
    "活動内容としては、各部門のデータ活用の取り組みや事例を紹介し合い、課題の改善に向けて議論しました。\n",
    "その結果、\n",
    "まず、各部門の取り組みの横展開に繋がったと思います。\n",
    "一例としては、Laprusをメカや技開に展開していく動きをかけることができました。\n",
    "また、EALデータ活用を浸透させる為に必要な施策が明確になったと思います。\n",
    "以降は②に関して報告していきます。\n",
    "\n",
    "まず、第一開発CのEALデータ活用の到達状況をここに示しています。\n",
    "EALデータを自分で分析できる人は各部門に数人程度です。\n",
    "分析できる人に依頼している人が多い、というのが実情です。\n",
    "データに触れる人は増えてきてはいるものの、腰を据えて分析できる人はまだまだ少ないです。\n",
    "また、せっかく分析したのに、テーマ設定が曖昧であり、アウトプットに繋がっていない事例も意外と多く見受けられような状況になっています。\n",
    "こうした状況になっている理由として、三つの側面に様々な課題が残っていると考えます。\n",
    "後半が報告のメインの話になりますが、EALのシステム面の課題から、順番に説明して行きます。\n",
    "\n",
    "EALデータはデータをダウンロードすることから難しいという課題があります。\n",
    "それは、データの理解が難しいため、ダウンロードも難しい、という状況になっています。\n",
    "EALチームが作成したダウンロードツールがあるのですが、使い方は、\n",
    "エクセルに、号機を指定し、コンテンツを指定し、実行すると、csvファイルが出力される、というものになります。\n",
    "ただし、コンテンツの理解が非常に難しく、コンテンツリストがあるものの、詳細はFW設計にきかなと分からないという課題があります。\n",
    "また、これが一台のデータですが、データの種類ごとにファイルが分かれており、どのファイルを見るべきかも、かなり難しさがあります。\n",
    "\n",
    "また、データ構造が複雑なため、分析することも難しいです。\n",
    "一例として、紙残量とJAM発生タイミングを分析する際の例を説明します。\n",
    "紙残量は1番のデータを見てグラフ化して、JAMは２番のデータを見てグラフ化して、加工して所望のグラフを作ることができます。\n",
    "ただし、ミスプリだったら４番、温度だったら１１番のデータ、というように、色んなファイルを見に行かないといけない難しさがあります。\n",
    "\n",
    "さらに、データ量が膨大なため、市場の全体傾向把握するのも難しいです。\n",
    "現状は二つの方法があり、一つはTableauビューを活用するという方法です。\n",
    "こちらは、準備してあるものに関しては狙い通りのことができますが、全ての個別案件に対して準備しきれない、という課題があります。\n",
    "二つ目は、全台数をダウンロードしてPythonで分析するという方法です。\n",
    "ダウンロード時間が非常にかかるという課題があります。2200の市場機全体をダウンロードすると７時間かかるとうい課題があります。\n",
    "\n",
    "システム面の課題をまとめると、こういった様々な課題があり、FW部門中心に改善活動が進められています。\n",
    "しかし、抜本的な改善まではまだまだ時間がかかるというのが実情だと思っています。\n",
    "\n",
    "続いて個人面の課題になります。\n",
    "分析スキルが足りない、という課題があると思います。\n",
    "スキルとしても、分析の技術的なスキルと、考え方のスキルの二つがあります。\n",
    "先ほど説明した通り、システム面の改善も進めていくものの、EALデータを分析するには個人のスキルアップも必須だと考えています。\n",
    "昨年度は、Pythonのスキルアップに必要なコンテンツの準備や、分析事例の公開を行いました。\n",
    "考え方の部分は、分析のワークフローなど、プロセスの提供等も必要なのではないかと考えているところになります。\n",
    "\n",
    "最後、組織面の課題になります。\n",
    "データ分析やってもアウトプットまで至らず、データのご利益を生み出しずらいという課題があると思います。\n",
    "これを解決するためは、各部門での組織的な活動が必要なのではないかと考えています。\n",
    "昨年度は、2200MLKチームで分析活動を行いました。\n",
    "チームで分析テーマを選定し、分析担当者を決め、分析を実行し、フォロー会を実施し、HPへの提案まで実現させることができました。\n",
    "データでこういったアウトプットを出せたのは、チーム活動として取り組めたからだと思っています。\n",
    "昨年は私が全体をサポートして実現させましたが、今年は、各部門で自走してもらう形で分析活動を実施してほしいと考えています。\n",
    "各部門で意思を持って推進していかないと進みづらいと思っているからです。\n",
    "この中で重要なのは、テーマを選定する、という部分だと思います。\n",
    "どんな提案を実現したいのか？技術面だけではなく、競合状況など他面的な視点で仮説立案してテーマを決めることが重要だと思っています。\n",
    "そこで、今年、技推での新しいミッションとして、\n",
    "各部門での分析活動に対して、技推が持つデータや競合情報を投げ込み、各部門の自走を後押しして活動を活性化させる取り組みをしたいと考えています。\n",
    "\n",
    "システム面、個人面、組織面の課題のまとめになります。\n",
    "今年の施策案としては、大きく、システム面での改善と、分析の考え方や組織的な取り組み方に対するフォロー、という二つの施策が考えられると思います。\n",
    "下の部分の取り組みに関して、技推として活動していける領域だと考えています。\n",
    "\n",
    "これを実現する体制の提案になります。\n",
    "この三つの課題に対して、システム面と技術的なスキルアップに関する部分に関してはFW部門やPython教育プランにお願いしたいと思っています。\n",
    "技推では、考え方面のスキルアップに関する施策提供や、各部門の分析活動への投げ込みを実施したいと考えています。\n",
    "各部門での分析活動を活性化させる施策案としては、各部門、所長にシェアするとか、良い事例はセンター会で共有する、等が考えられると思います。\n",
    "ポイントはここだと思っていまして、技推から積極的に投げ込みをしたいと思っていますが、分析は各部門で自走してもらいたいので、\n",
    "松本所長から各部門に意思入れをお願いしたいです。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
